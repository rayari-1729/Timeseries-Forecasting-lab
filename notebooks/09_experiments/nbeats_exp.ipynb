{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hxJmjxf3ykPq"
      },
      "outputs": [],
      "source": [
        "!pip install neuralforecast utilsforecast datasetsforecast"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from datasetsforecast.m3 import M3\n",
        "from datasetsforecast.m4 import M4\n",
        "\n",
        "from utilsforecast.losses import mae, smape\n",
        "from utilsforecast.evaluation import evaluate\n",
        "\n",
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.models import NBEATS"
      ],
      "metadata": {
        "id": "zFLI7OiB0JQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(name):\n",
        "    if name == 'M3-yearly':\n",
        "        Y_df, *_ = M3.load(\"./data\", \"Yearly\")\n",
        "        horizon = 6\n",
        "        freq = 'Y'\n",
        "    elif name == 'M3-quarterly':\n",
        "        Y_df, *_ = M3.load(\"./data\", \"Quarterly\")\n",
        "        horizon = 8\n",
        "        freq = 'Q'\n",
        "    elif name == 'M3-monthly':\n",
        "        Y_df, *_ = M3.load(\"./data\", \"Monthly\")\n",
        "        horizon = 18\n",
        "        freq = 'M'\n",
        "    elif name == 'M4-yearly':\n",
        "        Y_df, *_ = M4.load(\"./data\", \"Yearly\")\n",
        "        Y_df['ds'] = Y_df['ds'].astype(int)\n",
        "        horizon = 6\n",
        "        freq = 1\n",
        "    elif name == 'M4-quarterly':\n",
        "        Y_df, *_ = M4.load(\"./data\", \"Quarterly\")\n",
        "        Y_df['ds'] = Y_df['ds'].astype(int)\n",
        "        horizon = 8\n",
        "        freq = 1\n",
        "    elif name == 'M4-monthly':\n",
        "        Y_df, *_ = M4.load(\"./data\", \"Monthly\")\n",
        "        Y_df['ds'] = Y_df['ds'].astype(int)\n",
        "        horizon = 18\n",
        "        freq = 1\n",
        "    elif name == 'M4-weekly':\n",
        "        Y_df, *_ = M4.load(\"./data\", \"Weekly\")\n",
        "        Y_df['ds'] = Y_df['ds'].astype(int)\n",
        "        horizon = 13\n",
        "        freq = 1\n",
        "    elif name == 'M4-daily':\n",
        "        Y_df, *_ = M4.load(\"./data\", \"Daily\")\n",
        "        Y_df['ds'] = Y_df['ds'].astype(int)\n",
        "        horizon = 14\n",
        "        freq = 1\n",
        "    elif name == 'M4-hourly':\n",
        "        Y_df, *_ = M4.load(\"./data\", \"Hourly\")\n",
        "        Y_df['ds'] = Y_df['ds'].astype(int)\n",
        "        horizon = 48\n",
        "        freq = 1\n",
        "\n",
        "    return Y_df, horizon, freq"
      ],
      "metadata": {
        "id": "J4um0Q0c0x1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAMES = ['NBEATS_identity',\n",
        "               'NBEATS_poly2', 'NBEATS_poly3', 'NBEATS_poly4',\n",
        "               'NBEATS_pwl2', 'NBEATS_pwl3', 'NBEATS_pwl4',\n",
        "               'NBEATS_changepoint2', 'NBEATS_changepoint3', 'NBEATS_changepoint4']\n",
        "for dataset in ['M4-hourly', 'M4-weekly', 'M4-quarterly', 'M4-monthly', 'M4-daily', 'M4-yearly', 'M3-yearly', 'M3-quarterly', 'M3-monthly']:\n",
        "\n",
        "    Y_df, horizon, freq = get_dataset(dataset)\n",
        "    test_df = Y_df.groupby('unique_id').tail(horizon)\n",
        "    train_df = Y_df.drop(test_df.index).reset_index(drop=True)\n",
        "    input_size = 2*horizon\n",
        "\n",
        "    nbeats_identity = NBEATS(\n",
        "        input_size=input_size,\n",
        "        h=horizon,\n",
        "        stack_types = ['identity', 'identity', 'identity'],\n",
        "        early_stop_patience_steps=3,\n",
        "        max_steps=1000,\n",
        "        alias=\"NBEATS_identity\"\n",
        "    )\n",
        "\n",
        "    nbeats_poly2 = NBEATS(\n",
        "        input_size=input_size,\n",
        "        h=horizon,\n",
        "        n_basis=2,\n",
        "        basis='polynomial',\n",
        "        stack_types = [\"identity\", \"trend\", \"seasonality\"],\n",
        "        early_stop_patience_steps=3,\n",
        "        max_steps=1000,\n",
        "        alias=\"NBEATS_poly2\"\n",
        "    )\n",
        "    nbeats_poly3 = NBEATS(\n",
        "        input_size=input_size,\n",
        "        h=horizon,\n",
        "        n_basis=3,\n",
        "        basis='polynomial',\n",
        "        stack_types = [\"identity\", \"trend\", \"seasonality\"],\n",
        "        early_stop_patience_steps=3,\n",
        "        max_steps=1000,\n",
        "        alias=\"NBEATS_poly3\"\n",
        "    )\n",
        "    nbeats_poly4 = NBEATS(\n",
        "        input_size=input_size,\n",
        "        h=horizon,\n",
        "        n_basis=4,\n",
        "        basis='polynomial',\n",
        "        stack_types = [\"identity\", \"trend\", \"seasonality\"],\n",
        "        early_stop_patience_steps=3,\n",
        "        max_steps=1000,\n",
        "        alias=\"NBEATS_poly4\"\n",
        "    )\n",
        "\n",
        "    nbeats_pwl2 = NBEATS(\n",
        "        input_size=input_size,\n",
        "        h=horizon,\n",
        "        n_basis=2,\n",
        "        basis='piecewise_linear',\n",
        "        stack_types = [\"identity\", \"trend\", \"seasonality\"],\n",
        "        early_stop_patience_steps=3,\n",
        "        max_steps=1000,\n",
        "        alias=\"NBEATS_pwl2\"\n",
        "    )\n",
        "    nbeats_pwl3 = NBEATS(\n",
        "        input_size=input_size,\n",
        "        h=horizon,\n",
        "        n_basis=3,\n",
        "        basis='piecewise_linear',\n",
        "        stack_types = [\"identity\", \"trend\", \"seasonality\"],\n",
        "        early_stop_patience_steps=3,\n",
        "        max_steps=1000,\n",
        "        alias=\"NBEATS_pwl3\"\n",
        "    )\n",
        "    nbeats_pwl4 = NBEATS(\n",
        "        input_size=input_size,\n",
        "        h=horizon,\n",
        "        n_basis=4,\n",
        "        basis='piecewise_linear',\n",
        "        stack_types = [\"identity\", \"trend\", \"seasonality\"],\n",
        "        early_stop_patience_steps=3,\n",
        "        max_steps=1000,\n",
        "        alias=\"NBEATS_pwl4\"\n",
        "    )\n",
        "\n",
        "    nbeats_changepoint2 = NBEATS(\n",
        "        input_size=input_size,\n",
        "        h=horizon,\n",
        "        n_basis=2,\n",
        "        basis='changepoint',\n",
        "        stack_types = [\"identity\", \"trend\", \"seasonality\"],\n",
        "        early_stop_patience_steps=3,\n",
        "        max_steps=1000,\n",
        "        alias=\"NBEATS_changepoint2\"\n",
        "    )\n",
        "    nbeats_changepoint3 = NBEATS(\n",
        "        input_size=input_size,\n",
        "        h=horizon,\n",
        "        n_basis=3,\n",
        "        basis='changepoint',\n",
        "        stack_types = [\"identity\", \"trend\", \"seasonality\"],\n",
        "        early_stop_patience_steps=3,\n",
        "        max_steps=1000,\n",
        "        alias=\"NBEATS_changepoint3\"\n",
        "    )\n",
        "    nbeats_changepoint4 = NBEATS(\n",
        "        input_size=input_size,\n",
        "        h=horizon,\n",
        "        n_basis=4,\n",
        "        basis='changepoint',\n",
        "        stack_types = [\"identity\", \"trend\", \"seasonality\"],\n",
        "        early_stop_patience_steps=3,\n",
        "        max_steps=1000,\n",
        "        alias=\"NBEATS_changepoint4\"\n",
        "    )\n",
        "\n",
        "    models = [nbeats_identity, nbeats_changepoint2, nbeats_changepoint3, nbeats_changepoint4,\n",
        "              nbeats_poly2, nbeats_poly3, nbeats_poly4, nbeats_pwl2, nbeats_pwl3, nbeats_pwl4]\n",
        "\n",
        "    nf = NeuralForecast(models=models, freq=freq)\n",
        "    nf.fit(train_df, val_size=horizon)\n",
        "    preds = nf.predict()\n",
        "    preds = preds.reset_index(drop=True)\n",
        "    test_df = pd.merge(test_df, preds, 'left', ['ds', 'unique_id'])\n",
        "\n",
        "    evaluation = evaluate(\n",
        "        test_df,\n",
        "        metrics=[mae, smape],\n",
        "        models=MODEL_NAMES,\n",
        "        target_col=\"y\",\n",
        "    )\n",
        "    evaluation = evaluation.drop(['unique_id'], axis=1).groupby('metric').mean().reset_index()\n",
        "    print(dataset)\n",
        "    print(evaluation)"
      ],
      "metadata": {
        "id": "mxCPo0WC1qw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DxDPy1dPBnGn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}